{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from random import shuffle, seed\n",
    "from statistics import mode\n",
    "\n",
    "# import regex\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEMMER = SnowballStemmer('english')\n",
    "# STEMMER = PorterStemmer()\n",
    "\n",
    "SEED = 9745\n",
    "TRAIN_FRACTION = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(file_name):\n",
    "    text = open(file_name).read().lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Get tokens without stop words\n",
    "    words = [STEMMER.stem(w)\n",
    "             for w in words if w not in stopwords.words('english')]\n",
    "\n",
    "    # A word most have 3 or more characters with one letter\n",
    "    words = [w for w in words if len(w) >= 3 and re.match(r'[^\\W\\d\\_]', w)]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_corpus(locations):\n",
    "    corpus = []\n",
    "\n",
    "    for location, category in locations:\n",
    "        files = glob(join(location, '*.txt'))\n",
    "        for file_name in tqdm_notebook(files, desc=category):\n",
    "            corpus.append((tokenize(file_name), category))\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_frequency_dist(corpus):\n",
    "    all_words = []\n",
    "\n",
    "    for words, label in corpus:\n",
    "        all_words += words\n",
    "\n",
    "    return FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(features, document):\n",
    "    words = set(document[0])\n",
    "    return {w: (w in words) for w in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29544d8462094148b7df8a06d102ad0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e86eddc31f4c74984c1cb9ee1be340"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = build_corpus([('data/Rel-Yes', 'Rel-Yes'),\n",
    "                       ('data/Rel-No', 'Rel-No')])\n",
    "shuffle(corpus)\n",
    "\n",
    "all_words = build_frequency_dist(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_sets = [(document_features(word_features, d), d[1]) for d in corpus]\n",
    "\n",
    "train_test_split = int(len(feature_sets) * TRAIN_FRACTION)\n",
    "\n",
    "train_set = feature_sets[:train_test_split]\n",
    "test_set = feature_sets[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk_classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(nltk_classifier, test_set)\n",
    "print(f'NLTK Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              figueiredo = True           Rel-Ye : Rel-No =      8.0 : 1.0\n",
      "                unattain = True           Rel-Ye : Rel-No =      8.0 : 1.0\n",
      "                isotherm = True           Rel-Ye : Rel-No =      8.0 : 1.0\n",
      "               distribut = False          Rel-No : Rel-Ye =      7.3 : 1.0\n",
      "                    krug = True           Rel-Ye : Rel-No =      6.2 : 1.0\n",
      "               misrepres = True           Rel-Ye : Rel-No =      6.2 : 1.0\n",
      "              villarroya = True           Rel-Ye : Rel-No =      6.2 : 1.0\n",
      "                 quantil = True           Rel-Ye : Rel-No =      5.0 : 1.0\n",
      "                  inform = False          Rel-No : Rel-Ye =      4.9 : 1.0\n",
      "             misidentiÔ¨Åc = True           Rel-Ye : Rel-No =      4.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nltk_classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn MultinomialNB Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier = SklearnClassifier(MultinomialNB())\n",
    "mnb_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(mnb_classifier, test_set)\n",
    "print(f'Sklearn MultinomialNB Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gnb_classifier = SklearnClassifier(GaussianNB())\n",
    "# gnb_classifier.train(train_set)\n",
    "\n",
    "# accuracy = nltk.classify.accuracy(gnb_classifier, test_set)\n",
    "# print(f'Sklearn GaussianNB Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn BernoulliNB Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "bnb_classifier = SklearnClassifier(BernoulliNB())\n",
    "bnb_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(bnb_classifier, test_set)\n",
    "print(f'Sklearn BernoulliNB Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn LogisticRegression Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = SklearnClassifier(LogisticRegression())\n",
    "lr_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(lr_classifier, test_set)\n",
    "print(f'Sklearn LogisticRegression Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn SGDClassifier Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier = SklearnClassifier(SGDClassifier())\n",
    "sgd_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(sgd_classifier, test_set)\n",
    "print(f'Sklearn SGDClassifier Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn SVC Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = SklearnClassifier(SVC())\n",
    "svc_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(svc_classifier, test_set)\n",
    "print(f'Sklearn SVC Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn LinearSVC Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "lsvc_classifier = SklearnClassifier(LinearSVC())\n",
    "lsvc_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(lsvc_classifier, test_set)\n",
    "print(f'Sklearn LinearSVC Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn NuSVC Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "nusvc_classifier = SklearnClassifier(NuSVC())\n",
    "nusvc_classifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(nusvc_classifier, test_set)\n",
    "print(f'Sklearn NuSVC Accuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
